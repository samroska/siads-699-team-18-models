{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNC6aZygbkdEQg07b/iEy/6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["University of Michigan\n","\n","Master of Applied Data Science\n","\n","SIADS699 - Capstone Project\n","\n","Andre Onofre, Samantha Roska, Sawsan Allam"],"metadata":{"id":"mep3CHlqWo3u"}},{"cell_type":"markdown","source":["This Notebook: Inference Function for Dermatoscopic Images"],"metadata":{"id":"FskZ6wOkWpz0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0GScE11z-gK"},"outputs":[],"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["# Import Libraries\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras import models\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","import os\n","import random"],"metadata":{"id":"NW9VQLv50H2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Directories\n","IMAGES_DIR = './Images/BCN20000-all-images-original/bcn_20k_train/'\n","IMAGES_ARRAY_DIR = './Images_Arrays/'\n","META_DATA_DIR = './Metadata/'\n","MODELS_DIR = './Models/'\n","TEST_IMAGES_DIR = './Images/Images_for_tests/'\n","TRAINING_RESULTS_DIR = './Training_Results/'"],"metadata":{"id":"Gpis3dAqQ9D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load model\n","final_model = tf.keras.models.load_model(MODELS_DIR + 'BCN20000-V104-ConvNeXtTiny.keras')"],"metadata":{"id":"oyP6x2vK0H0b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classes Dictionary\n","BCN_classes_dict = {0: 'AK', 1: 'BCC', 2: 'BKL', 3: 'DF', 4: 'MEL',\n","                    5: 'NV', 6: 'SCC', 7: 'VASC'}"],"metadata":{"id":"YT-lQs9A18TX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inference Function\n","def inference_BCN(image_path, model, classes_dict):\n","  image = Image.open(image_path).convert('RGB') # read image & convert to RGB\n","  image_array_writable = img_to_array(image).copy()\n","  inference_image_resized = tf.image.resize(image_array_writable,[112,112]) # resize to model input shape\n","  inference_image_array = inference_image_resized.numpy().reshape(1,112,112,3) # convert to array\n","  inference_image_array_normalized = convnext_preprocess(inference_image_array) # normalize\n","  prediction = model.predict(inference_image_array_normalized) # Predict\n","  most_probable = np.argmax(prediction)\n","  print('\\nProbabilities:')\n","  print('AK: ' + str(round(prediction[0][0],3)))\n","  print('BCC: ' + str(round(prediction[0][1],3)))\n","  print('BKL: ' + str(round(prediction[0][2],3)))\n","  print('DF: ' + str(round(prediction[0][3],3)))\n","  print('MEL: ' + str(round(prediction[0][4],3)))\n","  print('NV: ' + str(round(prediction[0][5],3)))\n","  print('SCC: ' + str(round(prediction[0][6],3)))\n","  print('VASC: ' + str(round(prediction[0][7],3)))\n","  print('Most probable class: ' + classes_dict[most_probable])\n","  return prediction"],"metadata":{"id":"npFBoukC0HyM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing"],"metadata":{"id":"PtCz_T3U7_r0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Metadata for the images\n","df = pd.read_csv(META_DATA_DIR + 'BCN20000-Metadata-One-Hot.csv')"],"metadata":{"id":"wLn2fhWW8aTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select 10 random images, classify them and compare with true class\n","all_images = os.listdir(IMAGES_DIR)\n","some_images = random.sample(all_images, 10)\n","for image in some_images:\n","  image_path = IMAGES_DIR + image\n","  print(image_path)\n","  prediction = inference_BCN(image_path, final_model,BCN_classes_dict)\n","  print('Actual Class: ' + df[df['bcn_filename']==image]['diagnosis'].item())\n","  print(\"\\n\")"],"metadata":{"id":"ZeXOZaiQ0Hv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test one image of each class"],"metadata":{"id":"6Bf54LkWJ-EU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-AK.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"6MrbuQrYufsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-BCC.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"O-blRxVDjnYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-BKL.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"6N1JxN7bjify"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-DF.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"b-PBMQ9hk-W-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-MEL.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"Vxmg-gwWk-Uu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-NV.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"W_rjNXwTk-Sa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-SCC.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"4i11VV2Kk-QG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = inference_BCN(TEST_IMAGES_DIR + 'BCN-VASC.jpg', final_model,BCN_classes_dict)"],"metadata":{"id":"dFejcWKuk-No"},"execution_count":null,"outputs":[]}]}