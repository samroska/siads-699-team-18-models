{"cells":[{"cell_type":"markdown","metadata":{"id":"TMGI6FOhUzFm"},"source":["University of Michigan\n","\n","Master of Applied Data Science\n","\n","SIADS699 - Capstone Project\n","\n","Andre Onofre, Samantha Roska, Sawsan Allam"]},{"cell_type":"markdown","metadata":{"id":"1FqZs5ULU1y1"},"source":["This Notebook: Machine Learning Model for Dermatoscopic Images\n","\n","Augmentation used"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syxsP3Rgguw1"},"outputs":[],"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGLTHWhrgx0s"},"outputs":[],"source":["# Import Libraries\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import balanced_accuracy_score\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_v2_preprocess\n","from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n","from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n","from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n","from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess"]},{"cell_type":"code","source":["# Directories\n","IMAGES_DIR = './Images/BCN20000-all-images-original/bcn_20k_train/'\n","IMAGES_ARRAY_DIR = './Images_Arrays/'\n","META_DATA_DIR = './Metadata/'\n","MODELS_DIR = './Models/'\n","TEST_IMAGES_DIR = './Images/Images_for_tests/'\n","TRAINING_RESULTS_DIR = './Training_Results/'"],"metadata":{"id":"ZSO42AJ0KvGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7WAS5Gr8McP"},"outputs":[],"source":["# Load Pictures Array from file (should be (12412, 112, 112, 3) and (12412,8))\n","\n","loaded_images_array = np.load(IMAGES_ARRAY_DIR + 'BCN20000_images_array (112_112).npy')\n","print(loaded_images_array.shape)\n","\n","loaded_labels_array = np.load(IMAGES_ARRAY_DIR + 'BCN20000_labels_array (112_112).npy')\n","print(loaded_labels_array.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjL80GyWkxiA"},"outputs":[],"source":["# Divide in Training and Test Set\n","X_train, X_test, y_train, y_test = train_test_split(loaded_images_array, loaded_labels_array, test_size=0.2, random_state=42,stratify=loaded_labels_array)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhd0KDGaXetY"},"outputs":[],"source":["# Calculate Class Weights based on training set\n","y_integers = np.argmax(y_train, axis=1)\n","class_weights = compute_class_weight('balanced', classes=np.unique(y_integers), y=y_integers)\n","d_class_weights = dict(enumerate(class_weights))\n","for class_idx, weight in d_class_weights.items():\n","    print(f'Class {class_idx}: {weight:.2f}')\n","\n","# Propagating to all samples\n","final_weights_train = np.array([d_class_weights[label] for label in y_integers])\n"]},{"cell_type":"code","source":["# Augmentation\n","data_augmentation = tf.keras.Sequential([\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1),\n","    layers.RandomTranslation(height_factor=0.1, width_factor=0.1)\n","  ])\n","\n","def augment_data(image, label, weight=None):\n","    image = data_augmentation(image, training=True)\n","    if weight is not None:\n","      return image, label, weight\n","    else:\n","      return image, label"],"metadata":{"id":"3gyNWytXLmBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cos6kiP5CZgL"},"outputs":[],"source":["def train_run_model(model_type,\n","                    X_train,\n","                    X_test,\n","                    y_train,\n","                    y_test,\n","                    Use_Class_Weights,\n","                    Class_Weights,\n","                    Use_Augmentation):\n","\n","  print('------------------------------------------------------------------')\n","  print('\\nTraining Model ', model_type)\n","\n","  # Load base model\n","  print('\\nLoading Base Model...')\n","  model_string = \"tf.keras.applications.\" + model_type + \"(input_shape=(112,112,3),include_top=False,weights='imagenet')\"\n","  base_model = eval(model_string)\n","  print('Base Model Loaded!')\n","  base_model.trainable = False\n","\n","  # Define the number of layers to train\n","  total_layers = len(base_model.layers)\n","  number_of_layers_not_to_train = int(0.2 * total_layers)\n","  base_model.trainable = True\n","  for layer in base_model.layers[0:number_of_layers_not_to_train]:\n","    layer.trainable = False\n","\n","  trainable_layer_count = 0\n","  for layer in base_model.layers:\n","    if layer.trainable:\n","        trainable_layer_count += 1\n","\n","  print('\\nTotal Layers: ', total_layers)\n","  print('Layers to Train: ', total_layers - number_of_layers_not_to_train)\n","  print('Layers marked as Trainable: ', trainable_layer_count)\n","\n","  # Include Top Layers (flatten, dense, softmax)\n","  print('\\nAdding Top Layers...')\n","  last_desired_layer = base_model.get_layer(base_model.layers[-1].name)\n","  last_output = last_desired_layer.output\n","  new_output = layers.Flatten()(last_output)\n","  new_output = layers.Dense(512,activation='relu')(new_output)\n","  new_output = layers.Dropout(0.2)(new_output)\n","  new_output = layers.Dense(8, activation = 'softmax')(new_output)\n","  final_model = Model(inputs=base_model.input, outputs=new_output)\n","  print('Model Architecture Built!')\n","\n","  # Trainable parameters\n","  trainable_params = sum([tf.size(w).numpy() for w in final_model.trainable_weights])\n","  print(f\"\\nTrainable Parameters: {trainable_params:,}\")\n","\n","  # Non-trainable parameters\n","  non_trainable_params = sum([tf.size(w).numpy() for w in final_model.non_trainable_weights])\n","  print(f\"Non-Trainable Parameters: {non_trainable_params:,}\")\n","\n","  # Total number of parameters (Trainable + Non-trainable)\n","  total_params = final_model.count_params()\n","  print(f\"Total Parameters: {total_params:,}\")\n","\n","  # Normalization\n","  if model_type == 'EfficientNetB2':\n","    X_train = efficientnet_preprocess(X_train)\n","    X_test = efficientnet_preprocess(X_test)\n","    print('\\nNormalization done for EfficientNetB2')\n","  elif model_type == 'EfficientNetB0':\n","    X_train = efficientnet_preprocess(X_train)\n","    X_test = efficientnet_preprocess(X_test)\n","    print('\\nNormalization done for EfficientNetB0')\n","  elif model_type == 'DenseNet121':\n","    X_train = densenet_preprocess(X_train)\n","    X_test = densenet_preprocess(X_test)\n","    print('\\nNormalization done for DenseNet121')\n","  elif model_type == 'MobileNetV2':\n","    X_train = mobilenet_v2_preprocess(X_train)\n","    X_test = mobilenet_v2_preprocess(X_test)\n","    print('\\nNormalization done for MobileNetV2')\n","  elif model_type == 'ConvNeXtTiny':\n","    X_train = convnext_preprocess(X_train)\n","    X_test = convnext_preprocess(X_test)\n","    print('\\nNormalization done for ConvNeXtTiny')\n","  else:\n","    print('\\nNormalization not done')\n","\n","  # Prepare final dataset\n","  BUFFER_SIZE = len(X_train)\n","  BATCH_SIZE = 128\n","\n","  # Use Class Weights or not\n","  if Use_Class_Weights:\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, Class_Weights))\n","    print('\\nClass Weights Enabled')\n","  else:\n","    print('\\nClass Weights Disabled')\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","\n","  # Augmentation\n","  if Use_Augmentation:\n","    train_dataset = train_dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","    print('\\nAugmentation Enabled')\n","  else:\n","    print('\\nAugmentation Disabled')\n","\n","  # Shuffle samples before each epoch\n","  train_dataset = train_dataset.shuffle(buffer_size=BUFFER_SIZE, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n","\n","  # Compile Model and Train\n","  print('\\nCompiling Model...')\n","  Adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","  final_model.compile(optimizer = Adam_optimizer,loss = 'categorical_crossentropy', metrics = ['accuracy',tf.keras.metrics.F1Score(average='weighted', name='f1_score')])\n","  lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1_score',factor=0.1,patience=10, mode='max',verbose=1)\n","  callback = [keras.callbacks.EarlyStopping(monitor='val_f1_score',patience=30, mode='max',restore_best_weights=True), lr_schedule]\n","  print('Model Compiled')\n","\n","  print('\\nTraining Model...')\n","  history = final_model.fit(train_dataset,epochs = 200,verbose = 1, validation_data=(X_test, y_test), callbacks=[callback])\n","\n","  # Evaluate Model\n","  print('-------------------------------------------')\n","  print('Results for ' + model_type)\n","  print('-------------------------------------------')\n","  print('\\nEvaluation')\n","  test_loss, test_accuracy, f1_score = final_model.evaluate(X_test, y_test, verbose=0)\n","  test_accuracy = round(test_accuracy,2)\n","  print('Test Accuracy: ', test_accuracy)\n","  f1_score = round(f1_score,2)\n","  print('F1 Score: ', f1_score)\n","\n","  #  Balanced Score\n","  y_pred = final_model.predict(X_test)\n","  y_pred_classes = np.argmax(y_pred, axis=1)\n","  y_test_classes = np.argmax(y_test, axis=1)\n","  balanced_accuracy = round(balanced_accuracy_score(y_test_classes, y_pred_classes),2)\n","  print('Balanced accuracy: ', balanced_accuracy)\n","\n","  # Accuracy per Class\n","  print('\\nAccuracy Per Class')\n","  cm = confusion_matrix(y_test_classes, y_pred_classes)\n","  true_positives = np.diag(cm)\n","  actual_instances_per_class = np.sum(cm, axis=1)\n","  accuracy_per_class = np.divide(true_positives, actual_instances_per_class)\n","  for i, acc in enumerate(accuracy_per_class):\n","    print(f\"Class {i}: {acc*100:.1f}% (Samples: {actual_instances_per_class[i]})\")\n","  accuracy_per_class_rounded = [round(x, 2) for x in accuracy_per_class]\n","\n","  # Plot Confusion Matrix\n","  print('\\nConfusion Matrix')\n","  cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7])\n","  cm_display.plot()\n","  plt.show()\n","\n","  # Save Model\n","  mmodel_name = MODELS_DIR + 'BCN20000-V103-' + model_type + '.keras'\n","  print('\\nSaving Model...')\n","  final_model.save(mmodel_name)\n","  print('Model Saved!')\n","\n","  return test_accuracy, balanced_accuracy, f1_score, *accuracy_per_class_rounded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"exbSvpfNWCTr"},"outputs":[],"source":["# Dataset to store results\n","data_schema = {\n","    'Model': pd.Series(dtype='str'),\n","    'Accuracy': pd.Series(dtype='float'),\n","    'Balanced_Accuracy': pd.Series(dtype='float'),\n","    'F1': pd.Series(dtype='float'),\n","    'Acc_0': pd.Series(dtype='float'),\n","    'Acc_1': pd.Series(dtype='float'),\n","    'Acc_2': pd.Series(dtype='float'),\n","    'Acc_3': pd.Series(dtype='float'),\n","    'Acc_4': pd.Series(dtype='float'),\n","    'Acc_5': pd.Series(dtype='float'),\n","    'Acc_6': pd.Series(dtype='float'),\n","    'Acc_7': pd.Series(dtype='float')\n","}\n","\n","df_results = pd.DataFrame(data_schema)"]},{"cell_type":"code","source":["# Train models\n","models_to_train = ['EfficientNetB2', 'EfficientNetB0','DenseNet121', 'MobileNetV2', 'ConvNeXtTiny']\n","\n","for model_to_train in models_to_train:\n","  results_list = []\n","  test_accuracy, balanced_accuracy, f1_score, acc_0, acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, acc_7  = train_run_model(model_to_train,\n","                                                                                                        X_train.copy(),\n","                                                                                                        X_test.copy(),\n","                                                                                                        y_train,\n","                                                                                                        y_test,\n","                                                                                                        Use_Class_Weights=False,\n","                                                                                                        Class_Weights=final_weights_train,\n","                                                                                                        Use_Augmentation=True)\n","\n","  # Record Results on dataset\n","  new_record_data = {\n","    'Model': model_to_train,\n","    'Accuracy': test_accuracy,\n","    'Balanced_Accuracy': balanced_accuracy,\n","    'F1': f1_score,\n","    'Acc_0': acc_0,'Acc_1': acc_1,'Acc_2': acc_2, 'Acc_3': acc_3, 'Acc_4': acc_4, 'Acc_5': acc_5, 'Acc_6': acc_6, 'Acc_7': acc_7}\n","  results_list.append(new_record_data)\n","  new_record_df = pd.DataFrame(results_list)\n","  df_results = pd.concat([df_results, new_record_df], ignore_index=True)\n","\n","# Save Results\n","df_results.to_csv(TRAINING_RESULTS_DIR + 'BCN20000-V103-Training_Results.csv', index=False)\n","print('\\nResults Saved')"],"metadata":{"id":"FMkvpVbDWcCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_results"],"metadata":{"id":"hqTs2FqsWepJ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1Y4NehvwYfCvWF3gv_eLHNyHjiOJZztbD","timestamp":1760462382725},{"file_id":"1XLesoIMKC5WvuwSivx0wgXaswcZj71VQ","timestamp":1760409275307},{"file_id":"1-2pHEqApAV0SfwcnJp0MazwuYQpmfZQI","timestamp":1760403881599},{"file_id":"15CMDdjOxy1Cs8ks78_Bl1-rZpL-Vayy_","timestamp":1759784848564}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}